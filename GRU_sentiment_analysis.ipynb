{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gru_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musicjae/korean_sentiment_analysis/blob/master/GRU_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsRsiqqxO2i7"
      },
      "source": [
        "# References  \r\n",
        "[1] # https://www.programcreek.com/python/example/106388/torchtext.data.Field\r\n",
        "  \r\n",
        "[2] https://simonjisu.github.io/nlp/2018/07/18/torchtext.html   \r\n",
        "\r\n",
        "[3] https://wikidocs.net/44249\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7rbjiNAD6I0",
        "outputId": "91cf1ffa-339d-4be4-9d55-f01db0e29972"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWqZN5fhFFdg"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1MNifJfReWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53bdd15-dc60-420d-a7e2-166f6a21e561"
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'nsmc' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z6APoj3FEq3",
        "outputId": "8a3c863a-9fe0-4250-bae4-1a91e63156d2"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.2.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQtc6m33FEXg"
      },
      "source": [
        "import pandas as pd\r\n",
        "from konlpy.tag import Okt\r\n",
        "from nltk import FreqDist\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import torch.nn as nn\r\n",
        "import torch\r\n",
        "from torchtext import data\r\n",
        "from torchtext.data import TabularDataset\r\n",
        "from torchtext.data import Iterator\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(action='ignore')\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "\r\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\r\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
      ],
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYTNgov-4aF-"
      },
      "source": [
        "# 새 섹션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj3XN6MAGEMh"
      },
      "source": [
        "# args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sevTnElHGE4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119dec58-f9ad-48fa-9dcc-39deb53db55a"
      },
      "source": [
        "import argparse\r\n",
        "import torch\r\n",
        "\r\n",
        "USE_CUDA = torch.cuda.is_available()\r\n",
        "print(USE_CUDA)\r\n",
        "\r\n",
        "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\r\n",
        "print('학습을 진행하는 기기:',device)\r\n",
        "\r\n",
        "parser = argparse.ArgumentParser(description='hyperparameters.....')\r\n",
        "args = parser.parse_args(\"\")\r\n",
        "\r\n",
        "# =========== Training ============ #\r\n",
        "\r\n",
        "args.batch_size = 128\r\n",
        "args.epochs = 10\r\n",
        "args.lr = 1e-3\r\n",
        "args.eps = 1e-8\r\n",
        "args.hidden_dim = 64\r\n",
        "args.embbed_dim = 64\r\n",
        "args.n_classes = 1\r\n",
        "args.dropout_p = 0.2\r\n",
        "args.n_layers = 1\r\n",
        "args.patience = 10\r\n",
        "\r\n",
        "args.total_steps = 1055 * args.epochs  # 총 훈련 스텝 =  배치반복 횟수 * 에폭 where 1055 is len(train_loader)\r\n"
      ],
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "학습을 진행하는 기기: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4J4_uCAFZUj"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0luSOjaRlVb"
      },
      "source": [
        "train_dt = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\r\n",
        "test_dt = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\r\n",
        "\r\n",
        "train_path = 'nsmc/ratings_train.txt'\r\n",
        "test_path = 'nsmc/ratings_test.txt'"
      ],
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHzYV-RBUSYV"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wKYwbShThfh"
      },
      "source": [
        "def preprocess(text):\r\n",
        "\r\n",
        "    text['document'] = text['document'].fillna(0)\r\n",
        "    text['document'] = text['document'].str.replace(pat = r'[^ ㄱ-ㅣ가-힣]+', repl=r' ', regex=True) # 한글을 제외한 나머지 제거\r\n",
        "    text['document'] = text['document'].str.replace(',','').astype(object)\r\n",
        "\r\n",
        "    return text\r\n",
        "\r\n",
        "train_dt = preprocess(train_dt)\r\n",
        "test_dt = preprocess(test_dt)"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0UFFeStRl8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5f47bb-7356-418b-d52e-2e72fdf132f4"
      },
      "source": [
        "train_dt=train_dt[['document','label']]\r\n",
        "print(len(train))\r\n",
        "test_dt=test_dt[['document','label']]"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQdb8_PaJYSg"
      },
      "source": [
        "train_y = train_dt.label\r\n",
        "test_y = test_dt.label"
      ],
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo6aZYEMcK_6",
        "outputId": "6769b8af-f4f1-4bf5-9a2a-77b0bd514822"
      },
      "source": [
        "len(test_y)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV4TE00kUy7c"
      },
      "source": [
        "### Custom Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPcxY9_b6X7J"
      },
      "source": [
        "#### Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJTkgBpO23vx"
      },
      "source": [
        "tok = Okt()\r\n",
        "def preprocessing_sen(sen):\r\n",
        "    stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\r\n",
        "    result=[]\r\n",
        "\r\n",
        "    temp= tok.morphs(sen)\r\n",
        "    result.append(temp)\r\n",
        "\r\n",
        "    return result    "
      ],
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nCcXjHt3woT",
        "outputId": "59dbcdd2-9f0f-4f69-a014-188a7c9a08a7"
      },
      "source": [
        "def preprocessing_entirity(df):\r\n",
        "    result = []\r\n",
        "    for sen in tqdm(df.document):\r\n",
        "        try:\r\n",
        "            result.append(preprocessing_sen(sen))\r\n",
        "        except:\r\n",
        "            result.append('NaN')\r\n",
        "\r\n",
        "    result = [x[0] for x in result]\r\n",
        "    return result\r\n",
        "\r\n",
        "processed_train = preprocessing_entirity(train_dt)\r\n",
        "processed_test = preprocessing_entirity(test_dt)"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150000/150000 [13:23<00:00, 186.74it/s]\n",
            "100%|██████████| 50000/50000 [04:19<00:00, 192.67it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkkkLIANHwrA",
        "outputId": "e6e4fb4b-3fd4-4f3d-f7d9-3856c7c0921e"
      },
      "source": [
        "processed_train[0:2]"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['아', '더빙', '진짜', '짜증나네요', '목소리'],\n",
              " ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍지', '않구나']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVjZwh246W_z"
      },
      "source": [
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(processed_train)\r\n",
        "#tokenizer.fit_on_texts(processed_test)"
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52JnrEoy7CHS"
      },
      "source": [
        " 각 정수는 전체 훈련 데이터에서 등장 빈도수가 높은 순서대로 부여되었기 때문에, 높은 정수가 부여된 단어들은 등장 빈도수가 매우 낮다는 것을 의미합니다. 여기서는 빈도수가 낮은 단어들은 자연어 처리에서 배제하고자 합니다. 등장 빈도수가 3회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFK65NtBHfRc"
      },
      "source": [
        "- 단어 집합(vocabulary)의 크기 : 97871\r\n",
        "  \r\n",
        "- 등장 빈도가 2번 이하인 희귀 단어의 수: 65669\r\n",
        "  \r\n",
        "- 단어 집합에서 희귀 단어의 비율: 67.09750590062428\r\n",
        "  \r\n",
        "- 전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.108513935768472"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13e_4dUSK5xa"
      },
      "source": [
        "#### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17hMjCuBIGhO"
      },
      "source": [
        "vocab_size= 97871-2"
      ],
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMXTS3jFIkod"
      },
      "source": [
        "train = tokenizer.texts_to_sequences(processed_train)\r\n",
        "test = tokenizer.texts_to_sequences(processed_test)"
      ],
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "1F0iOY7XOEZT",
        "outputId": "6ce0af36-3ab5-4039-9938-45a65d421ba4"
      },
      "source": [
        "print('리뷰의 최대 길이 :',max(len(l) for l in train))\r\n",
        "print('리뷰의 평균 길이 :',sum(map(len, train))/len(train))\r\n",
        "plt.hist([len(s) for s in train], bins=50)\r\n",
        "plt.xlabel('length of samples')\r\n",
        "plt.ylabel('number of samples')\r\n",
        "plt.show()"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 79\n",
            "리뷰의 평균 길이 : 12.767146666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTQ9i8uBIo7a",
        "outputId": "8284a6e2-7bd6-432d-b67f-323e4cf9a8c6"
      },
      "source": [
        "print(train[0:2])\r\n",
        "print(len(train))\r\n",
        "print(len(test))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[50, 438, 18, 6858, 643], [889, 439, 46, 591, 2, 199, 1547, 23, 963, 6059, 25704]]\n",
            "150000\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG4Wh093OG-G"
      },
      "source": [
        "#### Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApU32aNgOIEa"
      },
      "source": [
        "max_len = 30\r\n",
        "\r\n",
        "train_X = train\r\n",
        "eval_X = test[:25000]\r\n",
        "test_X = test[25000:]\r\n",
        "\r\n",
        "train_y = train_dt.label\r\n",
        "\r\n",
        "test_y = test_dt.label\r\n",
        "eval_y = test_y[:25000]\r\n",
        "test_y = test_y[25000:]\r\n",
        "\r\n",
        "train_X = pad_sequences(train_X, maxlen = max_len,padding='post')\r\n",
        "eval_X = pad_sequences(eval_X, maxlen=max_len,padding='post')\r\n",
        "test_X = pad_sequences(test_X, maxlen = max_len,padding='post')"
      ],
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8DpmHI1-Y_D"
      },
      "source": [
        "class mydataset(Dataset):\r\n",
        "\r\n",
        "    def __init__(self,X,y):\r\n",
        "        self.data = X\r\n",
        "        self.target = y\r\n",
        "       \r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "\r\n",
        "        x = self.data[index]\r\n",
        "        y = self.target[index]\r\n",
        "\r\n",
        "        return x,y\r\n",
        "\r\n",
        "    def __len__ (self):\r\n",
        "\r\n",
        "        return len(self.data)\r\n"
      ],
      "execution_count": 376,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjAWDkUK1v8T"
      },
      "source": [
        "ctrain_set = mydataset(train_X,train_y)\r\n",
        "ceval_set = mydataset(eval_X,eval_y)\r\n",
        "ctest_set = mydataset(test_X,test_y)"
      ],
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkA0xdyx2CNZ",
        "outputId": "8d45ac17-ef4d-4213-a55a-73f6376ce180"
      },
      "source": [
        "train_loader = DataLoader(ctrain_set,args.batch_size,shuffle=True)\r\n",
        "eval_loader = DataLoader(ceval_set,args.batch_size)\r\n",
        "test_loader = DataLoader(ctest_set,args.batch_size)\r\n",
        "\r\n",
        "print(len(train_loader.dataset))\r\n",
        "print(len(eval_loader.dataset))\r\n",
        "print(len(test_loader.dataset))"
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150000\n",
            "25000\n",
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ4OuHTVL7lt"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za-pS2SSL8Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749d6841-a6ab-417f-aa8a-81fcec7ad97d"
      },
      "source": [
        "vocab_size = len(ctrain_set)\r\n",
        "\r\n",
        "\r\n",
        "class GRU(nn.Module):\r\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\r\n",
        "        super(GRU, self).__init__()\r\n",
        "        self.n_layers = n_layers\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "\r\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\r\n",
        "        self.dropout = nn.Dropout(dropout_p)\r\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\r\n",
        "                          num_layers=self.n_layers,\r\n",
        "                          batch_first=True)\r\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "        \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.embed(x)\r\n",
        "        h_0 = self._init_state(batch_size=x.size(0)) # 첫번째 히든 스테이트를 0벡터로 초기화\r\n",
        "        x, _ = self.gru(x, h_0)  # GRU의 리턴값은 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\r\n",
        "        h_t = x[:,-1,:] # (배치 크기, 은닉 상태의 크기)의 텐서로 크기가 변경됨. 즉, 마지막 time-step의 은닉 상태만 가져온다.\r\n",
        "        self.dropout(h_t)\r\n",
        "        logit = self.sigmoid(self.out(h_t))  # (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\r\n",
        "\r\n",
        "        return logit\r\n",
        "\r\n",
        "    def _init_state(self, batch_size=1):\r\n",
        "        weight = next(self.parameters()).data\r\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\r\n",
        "\r\n",
        "\r\n",
        "model = GRU(args.n_layers, args.hidden_dim, vocab_size, args.embbed_dim, args.n_classes, args.dropout_p)\r\n",
        "print(model)"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GRU(\n",
            "  (embed): Embedding(150000, 64)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (gru): GRU(64, 64, batch_first=True)\n",
            "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDj_futA90xO"
      },
      "source": [
        "class LSTM(nn.Module):\r\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\r\n",
        "        super(LSTM, self).__init__()\r\n",
        "        self.n_layers = n_layers\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "\r\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\r\n",
        "        self.dropout = nn.Dropout(dropout_p)\r\n",
        "        self.lstm = nn.LSTM(embed_dim, self.hidden_dim,\r\n",
        "                          num_layers=self.n_layers,\r\n",
        "                          batch_first=True)\r\n",
        "        \r\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "        \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.embed(x)\r\n",
        "        h_0 = self._init_state(batch_size=x.size(0)) # 첫번째 히든 스테이트를 0벡터로 초기화\r\n",
        "        c_0 = self._init_state(batch_size=x.size(0))\r\n",
        "        x, (h_out,_) = self.lstm(x, (c_0,h_0))  # GRU의 리턴값은 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\r\n",
        "        self.dropout(h_t)\r\n",
        "        logit = self.sigmoid(self.out(h_t))  # (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\r\n",
        "\r\n",
        "        return logit\r\n",
        "\r\n",
        "    def _init_state(self, batch_size=1):\r\n",
        "        weight = next(self.parameters()).data\r\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\r\n",
        "\r\n"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWXp9srMQCKf"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265XKn91YSqA"
      },
      "source": [
        "#### Ealry Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkje8KoaX_F3"
      },
      "source": [
        "class EarlyStopping:\r\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, patience=7, verbose=False):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            patience (int): How long to wait after last time validation loss improved.\r\n",
        "                            Default: 7\r\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \r\n",
        "                            Default: False\r\n",
        "        \"\"\"\r\n",
        "        self.patience = patience\r\n",
        "        self.verbose = verbose\r\n",
        "        self.counter = 0\r\n",
        "        self.best_score = None\r\n",
        "        self.early_stop = False\r\n",
        "        self.val_loss_min = np.Inf\r\n",
        "\r\n",
        "    def __call__(self, val_loss, model):\r\n",
        "\r\n",
        "        score = -val_loss\r\n",
        "\r\n",
        "        if self.best_score is None:\r\n",
        "            self.best_score = score\r\n",
        "            self.save_checkpoint(val_loss, model)\r\n",
        "        elif score < self.best_score:\r\n",
        "            self.counter += 1\r\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\r\n",
        "            if self.counter >= self.patience:\r\n",
        "                self.early_stop = True\r\n",
        "        else:\r\n",
        "            self.best_score = score\r\n",
        "            self.save_checkpoint(val_loss, model)\r\n",
        "            self.counter = 0\r\n",
        "\r\n",
        "    def save_checkpoint(self, val_loss, model):\r\n",
        "        '''Saves model when validation loss decrease.'''\r\n",
        "        if self.verbose:\r\n",
        "            print(\r\n",
        "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\r\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\r\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM57WxMHZAgF"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8T-1eLgZ7_f"
      },
      "source": [
        "earlystop = EarlyStopping(patience=args.patience, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "W2N_9jriQByL",
        "outputId": "a9cd3670-0d27-4087-f0ed-53195e5bd1b1"
      },
      "source": [
        "model_path = '/content/drive/MyDrive/models'\r\n",
        "optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "model.to(device)\r\n",
        "train_losses=[]\r\n",
        "val_losses = []\r\n",
        "val_accuracies = []\r\n",
        "avg_losses=[]\r\n",
        "total_loss = 0\r\n",
        "\r\n",
        "for epoch in range(args.epochs):\r\n",
        "\r\n",
        "    model.train()\r\n",
        "    for idx, batch in enumerate(train_loader):\r\n",
        "\r\n",
        "        text = batch[0].to(torch.int64).to(device)\r\n",
        "        label = batch[1].to(device)\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        output = model(text)\r\n",
        "        loss = criterion(output,label)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if idx % 1000 == 0:\r\n",
        "            print('Batch: %d      Loss: %5.5f' % (idx,loss))\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    corrects,val_loss = 0, 0\r\n",
        "    for idx,batch in enumerate(eval_loader):\r\n",
        "        \r\n",
        "        text = batch[0].to(torch.int64).to(device)\r\n",
        "        label = batch[1].to(device)\r\n",
        "        \r\n",
        "        output = model(text)\r\n",
        "        val_loss = criterion(output, label)\r\n",
        "        total_loss += val_loss.item()\r\n",
        "        corrects += (output.max(1)[1].view(label.size()).data == label.data).sum()\r\n",
        "\r\n",
        "    train_losses.append(loss)\r\n",
        "    val_losses.append(val_loss)\r\n",
        "        \r\n",
        "    size = len(eval_loader.dataset)\r\n",
        "    avg_loss = total_loss / size\r\n",
        "    avg_losses.append(avg_loss)\r\n",
        "    avg_accuracy = 100.0 * corrects / size\r\n",
        "    print(\"===== epoch: %d   validation_avg_loss: %5.6f     validation_avg_accuracy:%5.2f ======\" % (epoch,avg_loss,avg_accuracy))\r\n",
        "\r\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/models/review sentiment analysis/txtclassification.pt')\r\n",
        "\r\n"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-389-cb2c0da702fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKp7kKPlji-q"
      },
      "source": [
        "plt.plot(train_losses)\r\n",
        "plt.plot(val_losses)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqWRJeM-k2zW"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAOQGP03l_YW"
      },
      "source": [
        "model_load_path = '/content/drive/MyDrive/models/review sentiment analysis/txtclassification.pt'\r\n",
        "model.load_state_dict(torch.load(model_load_path))\r\n",
        "\r\n",
        "model.eval()\r\n",
        "corrects,val_loss = 0, 0\r\n",
        "for idx,batch in enumerate(zip(test_loader.dataset.data,test_loader.dataset.target)):\r\n",
        "    \r\n",
        "    text = torch.Tensor(batch[0]).to(torch.int64).to(device).unsqueeze(1)\r\n",
        "    print(text.dim())\r\n",
        "    label = torch.Tensor(batch[1]).to(torch.int64).to(device)\r\n",
        "    print(label)\r\n",
        "    \r\n",
        "    #label = torch.ensor(batch[1]).to(device)\r\n",
        "        \r\n",
        "    output = model(text)\r\n",
        "    val_loss = criterion(output, label)\r\n",
        "    total_loss += val_loss.item()\r\n",
        "    corrects += (output.max(1)[1].view(label.size()).data == label.data).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB37OIrwpZRi"
      },
      "source": [
        "\r\n",
        "def load_checkpoint(filepath):\r\n",
        "    model.load_state_dict(torch.load(filepath))\r\n",
        "    for parameter in model.parameters():\r\n",
        "        parameter.requires_grad = False\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    return model\r\n",
        "\r\n",
        "model = load_checkpoint(model_load_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUXjP6Bgk2i_"
      },
      "source": [
        "def sentiment_predict(model,new_sentence):\r\n",
        "  new_sentence = tok.morphs(new_sentence) # 토큰화\r\n",
        "  encoded = tokenizer.texts_to_sequences(new_sentence) # 정수 인코딩\r\n",
        "  encoded = [[x[0] for x in encoded]]\r\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len,padding='post') # 패딩\r\n",
        "  pad_new = torch.FloatTensor(pad_new).to(torch.int64).to(device)\r\n",
        "\r\n",
        "  print(pad_new)\r\n",
        "  score = model(pad_new) # 예측\r\n",
        "  print(score)\r\n",
        "  if(score > 0.5):\r\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\r\n",
        "  else:\r\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))\r\n",
        "\r\n",
        "\r\n",
        "textin = '이 영화 정말 재미있따'\r\n",
        "sentiment_predict(model,textin)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}